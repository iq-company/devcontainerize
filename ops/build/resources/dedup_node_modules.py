#!/usr/bin/env python3
"""Optimize node_modules across Frappe bench apps.

After `bench setup requirements --node` + `bench build`, every app gets its
own node_modules/ directory.  This script reduces image size by:

  1. **Dedup** – Identical packages (same name + version) across apps are
     replaced with relative symlinks to a single canonical copy.
  2. **Clean** – Unnecessary files (tests, source maps, docs, CI configs)
     are removed from ALL node_modules trees (including nested ones).

Run AFTER `bench build` so the build can resolve packages normally.

Usage:
    python3 dedup_node_modules.py <apps-directory>

Example:
    python3 dedup_node_modules.py /home/iqa/bench/apps
"""

import json
import os
import shutil
import sys
from collections import defaultdict
from pathlib import Path

# ---------------------------------------------------------------------------
# Cleanup configuration
# ---------------------------------------------------------------------------

# Directory names to remove entirely (case-sensitive)
REMOVE_DIRS = {
    "test", "tests", "__tests__", "testing",
    "example", "examples",
    ".github", ".circleci", ".nyc_output",
    "coverage", "benchmark", "benchmarks",
    "powered-test",
}

# File glob patterns to remove
REMOVE_FILE_GLOBS = [
    "*.map",          # source maps  (~68 MB)
    "*.md",           # readmes, changelogs, etc.  (~14 MB)
    "*.markdown",
    "*.ts.map",
    ".travis.yml",
    ".eslintrc*",
    ".prettierrc*",
    ".editorconfig",
    ".npmignore",
    ".gitattributes",
    "CHANGELOG*",
    "CHANGES*",
    "HISTORY*",
    "LICENSE*",        # not needed at runtime, license info is in package.json
    "LICENCE*",
    "AUTHORS*",
    "CONTRIBUTORS*",
    "Makefile",
    "Gruntfile*",
    "Gulpfile*",
    "karma.conf*",
    "jest.config*",
    "tsconfig.json",   # not needed at runtime
    "tslint.json",
    ".babelrc",
    "rollup.config*",
    "webpack.config*",
]

# File extensions to remove (matched via suffix, faster than glob)
REMOVE_EXTENSIONS = {
    ".map",
    ".md",
    ".markdown",
}

# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------


def _read_pkg_meta(pkg_json: Path) -> tuple[str | None, str | None]:
    """Read 'name' and 'version' from a package.json.

    Returns (name, version) or (None, None) on error.
    Using the *npm* name (not the directory name) ensures that aliases
    like ``wrap-ansi-cjs`` (which is really ``wrap-ansi``) are matched
    correctly during deduplication.
    """
    try:
        if pkg_json.is_file():
            data = json.loads(pkg_json.read_text())
            return data.get("name"), data.get("version")
    except (json.JSONDecodeError, OSError):
        pass
    return None, None


def _dir_size(path: Path) -> int:
    """Return total size (bytes) of all regular files under *path*."""
    return sum(f.stat().st_size for f in path.rglob("*") if f.is_file())


# ---------------------------------------------------------------------------
# 1. Find all node_modules trees
# ---------------------------------------------------------------------------


def _is_top_level_nm(nm_dir: Path, apps_dir: Path) -> bool:
    """Return True if nm_dir is a top-level app node_modules.

    Top-level means ``apps/<app>/node_modules`` (direct child of an app).
    Sub-app trees like ``apps/frappe/billing/node_modules`` return False.
    """
    try:
        rel = nm_dir.relative_to(apps_dir)
        # Top-level: e.g. "frappe/node_modules" → 2 parts
        return len(rel.parts) == 2
    except ValueError:
        return False


def find_all_node_modules(apps_dir: Path) -> list[Path]:
    """Return all node_modules directories under apps_dir.

    Includes top-level (apps/<app>/node_modules) and sub-directories
    like apps/frappe/billing/node_modules.  Skips symlinked trees.

    **Order guarantee**: Top-level app node_modules come first (sorted),
    followed by sub-app node_modules (sorted).  This ensures that
    ``dedup()`` always picks a top-level tree as the canonical copy.
    """
    top_level = []
    sub_app = []
    for nm in sorted(apps_dir.rglob("node_modules")):
        # Only consider real directories, skip symlinks and nested nm inside nm
        if nm.is_symlink():
            continue
        # Skip nested node_modules (nm/pkg/node_modules) – those are handled
        # when we recurse into the parent nm for cleaning.
        # We only want the "root" node_modules per app (or sub-app like billing).
        parts = nm.parts
        nm_count = parts.count("node_modules")
        if nm_count == 1:
            if _is_top_level_nm(nm, apps_dir):
                top_level.append(nm)
            else:
                sub_app.append(nm)
    # Top-level first → they become canonical in dedup()
    return top_level + sub_app


# ---------------------------------------------------------------------------
# 2. Deduplication (top-level packages across apps)
# ---------------------------------------------------------------------------


def iter_top_level_packages(nm_dirs: list[Path]):
    """Yield (nm_label, npm_name, version, pkg_path) for every top-level
    package in every node_modules directory.

    Uses the *npm* ``name`` field from ``package.json`` – not the directory
    name – so that npm aliases (e.g. ``wrap-ansi-cjs`` → ``wrap-ansi``)
    are grouped correctly during deduplication.
    """

    for nm_dir in nm_dirs:
        # Label for display (e.g. "frappe", "frappe/billing", "iq_core")
        label = "/".join(nm_dir.parent.relative_to(nm_dir.parents[1]).parts)

        for entry in sorted(nm_dir.iterdir()):
            if entry.name.startswith(".") or entry.is_symlink():
                continue

            if entry.name.startswith("@"):
                # Scoped package (@scope/name)
                if not entry.is_dir():
                    continue
                for sub in sorted(entry.iterdir()):
                    if sub.is_symlink() or not sub.is_dir():
                        continue
                    npm_name, version = _read_pkg_meta(sub / "package.json")
                    if npm_name and version:
                        yield label, npm_name, version, sub
            else:
                if not entry.is_dir():
                    continue
                npm_name, version = _read_pkg_meta(entry / "package.json")
                if npm_name and version:
                    yield label, npm_name, version, entry


def dedup(nm_dirs: list[Path]) -> tuple[int, int]:
    """Deduplicate identical packages across node_modules directories."""

    groups: dict[tuple[str, str], list[tuple[str, Path]]] = defaultdict(list)
    for label, pkg_name, version, pkg_path in iter_top_level_packages(nm_dirs):
        groups[(pkg_name, version)].append((label, pkg_path))

    deduped_count = 0
    saved_bytes = 0

    for (pkg_name, version), entries in sorted(groups.items()):
        if len(entries) < 2:
            continue

        canonical_label, canonical_path = entries[0]

        for dup_label, dup_path in entries[1:]:
            pkg_size = _dir_size(dup_path)
            shutil.rmtree(dup_path)

            rel_target = os.path.relpath(canonical_path, dup_path.parent)
            os.symlink(rel_target, dup_path)

            deduped_count += 1
            saved_bytes += pkg_size
            print(f"  {pkg_name}@{version}: {dup_label} → {canonical_label}")

    return deduped_count, saved_bytes


# ---------------------------------------------------------------------------
# 3. Nested dedup: replace nested packages with symlinks to top-level
# ---------------------------------------------------------------------------


def _collect_all_packages(nm_dirs: list[Path], apps_dir: Path) -> dict[tuple[str, str], list[Path]]:
    """Collect every package instance (top-level AND nested) across all trees.

    Returns {(npm_name, version): [path, ...]} where the first entry is the
    canonical copy.

    **Ordering**: packages from top-level app node_modules (``apps/<app>/
    node_modules``) appear first in each list, so they are always preferred
    as canonical copies over sub-app trees (like ``frappe/billing/node_modules``).
    This prevents broken symlinks in devcontainer volumes where sub-app
    directories may not exist.
    """
    groups: dict[tuple[str, str], list[Path]] = defaultdict(list)

    def _scan_dir(nm_dir: Path):
        """Recursively scan a node_modules directory for packages."""
        if not nm_dir.is_dir() or nm_dir.is_symlink():
            return
        for entry in sorted(nm_dir.iterdir()):
            if entry.is_symlink() or not entry.is_dir():
                continue
            if entry.name.startswith("."):
                continue

            if entry.name.startswith("@"):
                # Scoped package (@scope/name)
                for sub in sorted(entry.iterdir()):
                    if sub.is_symlink() or not sub.is_dir():
                        continue
                    npm_name, version = _read_pkg_meta(sub / "package.json")
                    if npm_name and version:
                        groups[(npm_name, version)].append(sub)
                    # Recurse into nested node_modules
                    nested = sub / "node_modules"
                    if nested.is_dir() and not nested.is_symlink():
                        _scan_dir(nested)
            else:
                npm_name, version = _read_pkg_meta(entry / "package.json")
                if npm_name and version:
                    groups[(npm_name, version)].append(entry)
                # Recurse into nested node_modules
                nested = entry / "node_modules"
                if nested.is_dir() and not nested.is_symlink():
                    _scan_dir(nested)

    # nm_dirs is already ordered: top-level first, sub-app second
    # (guaranteed by find_all_node_modules).
    # Phase 1: collect top-level packages from ALL nm_dirs (they get first slots)
    for nm_dir in nm_dirs:
        for entry in sorted(nm_dir.iterdir()):
            if entry.is_symlink() or not entry.is_dir() or entry.name.startswith("."):
                continue
            if entry.name.startswith("@"):
                for sub in sorted(entry.iterdir()):
                    if sub.is_symlink() or not sub.is_dir():
                        continue
                    npm_name, version = _read_pkg_meta(sub / "package.json")
                    if npm_name and version:
                        groups[(npm_name, version)].append(sub)
            else:
                npm_name, version = _read_pkg_meta(entry / "package.json")
                if npm_name and version:
                    groups[(npm_name, version)].append(entry)

    # Phase 2: collect nested packages (appended after top-level → never canonical
    # unless no top-level copy exists)
    for nm_dir in nm_dirs:
        for entry in sorted(nm_dir.iterdir()):
            if entry.is_symlink() or not entry.is_dir() or entry.name.startswith("."):
                continue
            if entry.name.startswith("@"):
                for sub in sorted(entry.iterdir()):
                    if sub.is_symlink() or not sub.is_dir():
                        continue
                    nested = sub / "node_modules"
                    if nested.is_dir() and not nested.is_symlink():
                        _scan_dir(nested)
            else:
                nested = entry / "node_modules"
                if nested.is_dir() and not nested.is_symlink():
                    _scan_dir(nested)

    return groups


def dedup_nested(nm_dirs: list[Path], apps_dir: Path) -> tuple[int, int]:
    """Replace duplicate packages with symlinks to a single canonical copy.

    Handles both:
    - **nested → top-level**: a nested package matches a top-level package
      in any app (e.g. ``frappe/yargs/node_modules/cliui`` → ``iq_core/cliui``)
    - **nested → nested**: multiple nested copies of the same package where
      no top-level version exists (e.g. 3× ``ws@8.11.0`` nested in
      socket.io-adapter, engine.io, engine.io-client)

    The first encountered copy (preferring top-level app node_modules)
    becomes canonical; all others are replaced with relative symlinks.

    Returns (replaced_count, bytes_saved).
    """
    groups = _collect_all_packages(nm_dirs, apps_dir)

    replaced = 0
    saved_bytes = 0

    for (npm_name, version), paths in sorted(groups.items()):
        # Filter to real (non-symlink) paths that still exist
        real = [p for p in paths if p.exists() and not p.is_symlink()]
        if len(real) < 2:
            continue

        canonical = real[0]

        for dup in real[1:]:
            pkg_size = _dir_size(dup)
            shutil.rmtree(dup)
            rel = os.path.relpath(canonical, dup.parent)
            os.symlink(rel, dup)
            replaced += 1
            saved_bytes += pkg_size

            try:
                # Pretty-print relative to apps dir
                apps_dir = nm_dirs[0].parents[1]
                dup_rel = dup.relative_to(apps_dir)
                canon_rel = canonical.relative_to(apps_dir)
                print(f"  {npm_name}@{version}: {dup_rel} → {canon_rel}")
            except ValueError:
                print(f"  {npm_name}@{version}: symlinked duplicate")

    return replaced, saved_bytes


# ---------------------------------------------------------------------------
# 4. Cleanup: remove test dirs, source maps, docs, CI configs (renumbered)
# ---------------------------------------------------------------------------


def _should_remove_file(name: str) -> bool:
    """Return True if a file should be removed based on name/extension."""
    if name.suffix in REMOVE_EXTENSIONS:
        return True
    name_str = name.name
    for pattern in REMOVE_FILE_GLOBS:
        if "*" in pattern:
            # Simple glob: *.ext or prefix*
            if pattern.startswith("*"):
                if name_str.endswith(pattern[1:]) or (pattern[1] == "." and name.suffix == pattern[1:]):
                    return True
            elif pattern.endswith("*"):
                if name_str.startswith(pattern[:-1]):
                    return True
        else:
            if name_str == pattern:
                return True
    return False


def clean(nm_dirs: list[Path]) -> tuple[int, int, int, int]:
    """Remove unnecessary files and directories from all node_modules trees.

    Returns (dirs_removed, files_removed, dirs_bytes, files_bytes).
    """
    dirs_removed = 0
    files_removed = 0
    dirs_bytes = 0
    files_bytes = 0

    for nm_dir in nm_dirs:
        # Walk ALL contents including nested node_modules
        for root, dirs, files in os.walk(nm_dir, topdown=True):
            root_path = Path(root)

            # Skip symlinked directories
            if root_path.is_symlink():
                dirs.clear()
                continue

            # Remove matching directories (prune from walk)
            remove_these = []
            for d in dirs:
                if d in REMOVE_DIRS:
                    dir_path = root_path / d
                    if dir_path.is_symlink():
                        continue
                    try:
                        size = _dir_size(dir_path)
                        shutil.rmtree(dir_path)
                        dirs_removed += 1
                        dirs_bytes += size
                    except OSError:
                        pass
                    remove_these.append(d)

            for d in remove_these:
                dirs.remove(d)

            # Remove matching files
            for f in files:
                file_path = root_path / f
                if file_path.is_symlink():
                    continue
                if _should_remove_file(file_path):
                    try:
                        size = file_path.stat().st_size
                        file_path.unlink()
                        files_removed += 1
                        files_bytes += size
                    except OSError:
                        pass

    return dirs_removed, files_removed, dirs_bytes, files_bytes


# ---------------------------------------------------------------------------
# 5. Prune devDependencies
# ---------------------------------------------------------------------------


def prune_dev_deps(nm_dirs: list[Path]) -> tuple[int, int]:
    """Remove devDependencies from each node_modules tree.

    Reads each app's package.json, finds packages listed ONLY in
    devDependencies (not also in dependencies), and removes them.
    In the dev image this is safe because init_site.sh re-runs
    yarn install which restores them in the mounted volume.

    Returns (packages_removed, bytes_saved).
    """
    removed_count = 0
    saved_bytes = 0

    for nm_dir in nm_dirs:
        pkg_json = nm_dir.parent / "package.json"
        if not pkg_json.is_file():
            continue

        try:
            data = json.loads(pkg_json.read_text())
        except (json.JSONDecodeError, OSError):
            continue

        dev_deps = set(data.get("devDependencies", {}).keys())
        prod_deps = set(data.get("dependencies", {}).keys())

        # Only remove packages that are exclusively dev dependencies
        prune_pkgs = dev_deps - prod_deps
        if not prune_pkgs:
            continue

        label = nm_dir.parent.name

        for pkg_name in sorted(prune_pkgs):
            # Handle scoped packages (@scope/name)
            pkg_path = nm_dir / pkg_name
            if not pkg_path.exists() or pkg_path.is_symlink():
                continue

            try:
                pkg_size = _dir_size(pkg_path)
                shutil.rmtree(pkg_path)
                removed_count += 1
                saved_bytes += pkg_size
                print(f"  {label}: {pkg_name} ({pkg_size / 1024:.0f} KB)")
            except OSError:
                pass

    return removed_count, saved_bytes


# ---------------------------------------------------------------------------
# 6. Strip SBOM metadata from build-artifact package.json files
# ---------------------------------------------------------------------------

# Fields that Trivy (and other SBOM tools) use to identify a package.
# Removing them from non-root package.json prevents phantom duplicates
# in CycloneDX / SPDX output while preserving Node.js module resolution.
SBOM_FIELDS = {"name", "version", "description", "author", "license",
               "licenses", "repository", "homepage", "bugs",
               "devDependencies", "peerDependencies", "optionalDependencies",
               "private", "gitHead", "nyc", "keywords"}

# Fields that Node.js actually needs for module/type resolution – keep these.
# "type", "main", "module", "exports", "types", "typings", "browser", "engines"


def _is_root_package_json(pj: Path) -> bool:
    """Return True if *pj* is the root package.json of an npm package.

    Root package.json lives directly inside a ``node_modules/<pkg>/`` or
    ``node_modules/@scope/<pkg>/`` directory.
    """
    # pj = .../node_modules/<pkg>/package.json          → parent.parent.name == "node_modules"
    # pj = .../node_modules/@scope/<pkg>/package.json   → parent.parent.parent.name == "node_modules"
    parent = pj.parent                    # the package directory
    grandparent = parent.parent           # node_modules or @scope
    if grandparent.name == "node_modules":
        return True
    if grandparent.name.startswith("@") and grandparent.parent.name == "node_modules":
        return True
    return False


def strip_sbom_from_build_artifacts(nm_dirs: list[Path]) -> int:
    """Remove name/version/… from non-root package.json inside node_modules.

    These files exist in ``build/``, ``dist/``, ``esm/``, ``cjs/`` etc.
    sub-directories and are used by Node.js only for the ``"type"`` field
    (ESM vs CJS).  Trivy however treats every ``package.json`` with a
    ``name`` + ``version`` as an independent package, creating phantom
    duplicates in the SBOM.

    Returns the number of files stripped.
    """
    stripped = 0

    for nm_dir in nm_dirs:
        for pj in nm_dir.rglob("package.json"):
            if pj.is_symlink():
                continue
            if _is_root_package_json(pj):
                continue

            try:
                data = json.loads(pj.read_text())
            except (json.JSONDecodeError, OSError):
                continue

            # Only strip if it actually has SBOM-relevant fields
            if not ({"name", "version"} & set(data.keys())):
                continue

            # Remove SBOM fields, keep everything else (type, main, module, …)
            cleaned = {k: v for k, v in data.items() if k not in SBOM_FIELDS}

            pj.write_text(json.dumps(cleaned, indent=2) + "\n")
            stripped += 1

    return stripped


# ---------------------------------------------------------------------------
# Main
# ---------------------------------------------------------------------------


def main():
    if len(sys.argv) < 2:
        print(f"Usage: {sys.argv[0]} <apps-directory>")
        sys.exit(1)

    apps_dir = Path(sys.argv[1])
    if not apps_dir.is_dir():
        print(f"Error: {apps_dir} is not a directory")
        sys.exit(1)

    # Discover all node_modules trees (including sub-apps like frappe/billing)
    nm_dirs = find_all_node_modules(apps_dir)
    print(f"Found {len(nm_dirs)} node_modules trees:")
    for nm in nm_dirs:
        print(f"  {nm.relative_to(apps_dir)}")

    # Phase 1: Deduplicate across trees (top-level packages, same npm name + version)
    print("\n--- Phase 1: Cross-app deduplication (top-level) ---")
    dedup_count, dedup_bytes = dedup(nm_dirs)
    dedup_mb = dedup_bytes / (1024 * 1024)
    print(f"Deduplicated {dedup_count} packages, saved ~{dedup_mb:.1f} MB")

    # Phase 2: Deduplicate nested packages against top-level (cross-app)
    print("\n--- Phase 2: Nested deduplication (nested → top-level) ---")
    nested_count, nested_bytes = dedup_nested(nm_dirs, apps_dir)
    nested_mb = nested_bytes / (1024 * 1024)
    print(f"Replaced {nested_count} nested packages, saved ~{nested_mb:.1f} MB")

    # Phase 3: Clean unnecessary files from all trees
    print("\n--- Phase 3: Cleanup ---")
    dirs_rm, files_rm, dirs_bytes, files_bytes = clean(nm_dirs)
    clean_mb = (dirs_bytes + files_bytes) / (1024 * 1024)
    print(f"Removed {dirs_rm} directories and {files_rm} files, saved ~{clean_mb:.1f} MB")

    # Phase 4: Prune devDependencies
    print("\n--- Phase 4: Prune devDependencies ---")
    prune_count, prune_bytes = prune_dev_deps(nm_dirs)
    prune_mb = prune_bytes / (1024 * 1024)
    print(f"Pruned {prune_count} devDependency packages, saved ~{prune_mb:.1f} MB")

    # Phase 5: Strip SBOM metadata from build-artifact package.json
    print("\n--- Phase 5: Strip SBOM metadata from build artifacts ---")
    stripped = strip_sbom_from_build_artifacts(nm_dirs)
    print(f"Stripped SBOM fields from {stripped} non-root package.json files")

    total_mb = (dedup_bytes + nested_bytes + dirs_bytes + files_bytes + prune_bytes) / (1024 * 1024)
    print(f"\n=== Total savings: ~{total_mb:.1f} MB ===")


if __name__ == "__main__":
    main()
